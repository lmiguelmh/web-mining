{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms for regex ' ^[hH]\\w+ ': 1039\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "f = open(\"Austen_Emma_copy.txt\")\n",
    "text = f.read()\n",
    "tokenizer = RegexpTokenizer(r'^[hH]\\w+')\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print \"terms for regex '\", tokenizer._pattern,\"':\", len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'help': 3, 'half': 11, 'horseback': 1, 'human': 1, 'happiness': 10, 'hypocrisy': 1, 'heedlessness': 1, 'had': 99, 'hereabouts': 2, 'honoured': 1, 'has': 14, 'hope': 8, 'happened': 3, 'horror': 1, 'hodges': 1, 'hands': 3, 'hindered': 1, 'hitherto': 3, 'him': 41, 'humph': 1, 'housekeeper': 2, 'hartfield': 22, 'habits': 1, 'harriet': 91, 'husband': 3, 'heavy': 2, 'habit': 1, 'house': 9, 'hard': 2, 'hurried': 2, 'hair': 1, 'honourable': 2, 'home': 9, 'happen': 2, 'hesitation': 1, 'health': 2, 'hill': 2, 'henceforward': 2, 'honour': 5, 'hurrying': 2, 'however': 17, 'here': 11, 'hours': 1, 'houses': 2, 'hospitable': 1, 'harshly': 1, 'handsomest': 2, 'hearing': 5, 'haunts': 1, 'honest': 1, 'hence': 3, 'hospitality': 1, 'humour': 1, 'humility': 1, 'highly': 4, 'heated': 1, 'hawkins': 2, 'honourably': 1, 'hundred': 1, 'hardly': 3, 'headache': 2, 'horses': 1, 'head': 1, 'himself': 14, 'happily': 2, 'highbury': 23, 'hoped': 3, 'hear': 6, 'hesitated': 1, 'hopes': 1, 'hurry': 1, 'herself': 25, 'handsome': 3, 'hour': 2, 'hesitating': 1, 'henry': 2, 'handwriting': 1, 'happy': 14, 'history': 1, 'heart': 4, 'hotter': 1, 'hoping': 1, 'horsewoman': 1, 'high': 3, 'heard': 7, 'have': 95, 'hesitate': 1, 'holds': 1, 'handed': 1, 'how': 27, 'higher': 1, 'heir': 1, 'hand': 1, 'husbands': 1, 'hurt': 1, 'hardships': 1, 'hungry': 1, 'hearts': 1, 'having': 18}\n99\n"
     ]
    }
   ],
   "source": [
    "tokens_low = []\n",
    "for word in tokens:\n",
    "    tokens_low.append(word.lower())\n",
    "\n",
    "stop_words = ['he', 'his', 'hers', 'her']\n",
    "tokens_low_without_stop_words = []\n",
    "for word in tokens_low:\n",
    "    if word not in stop_words:\n",
    "        tokens_low_without_stop_words.append(word)\n",
    "        \n",
    "\n",
    "count = {}\n",
    "for word in tokens_low_without_stop_words:\n",
    "    if word in count:\n",
    "        count[word] += 1\n",
    "    else:\n",
    "        count[word] = 1\n",
    "\n",
    "print count\n",
    "print len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}